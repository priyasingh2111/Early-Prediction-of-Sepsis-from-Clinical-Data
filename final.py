# -*- coding: utf-8 -*-
"""final

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oxDZJKScuCrwBCIPJ6dMOfeQ7R7m9J6V
"""

import pandas as pd
import seaborn as sns 
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, roc_auc_score, mean_absolute_error, mean_squared_error
from sklearn.preprocessing import StandardScaler
import scipy.stats as stats
from sklearn.metrics import roc_curve
from sklearn.metrics import RocCurveDisplay
from sklearn.metrics import roc_auc_score

combined = pd.read_csv('data/Dataset.csv')

rows_to_drop = combined.loc[combined['Patient_ID'].apply(lambda x: len(str(x)) == 6)]
df_train = combined.drop(rows_to_drop.index)
df_train.to_csv('data/data_part1.csv', index=False)

rows_to_drop = combined.loc[combined['Patient_ID'].apply(lambda x: len(str(x)) != 6)]
df_test = combined.drop(rows_to_drop.index)
df_test.to_csv('data/data_part2.csv', index=False)

df_train = pd.read_csv('data/data_part1.csv')
df_test = pd.read_csv('data/data_part2.csv')

df_train.head(15)

df_train.columns

patients = list(df_test['Patient_ID'].unique())
len(patients)

null_values = df_train.isnull().mean()*100
null_values = null_values.sort_values(ascending=False)
null_values

columns_drop={'Unnamed: 0','SBP','DBP','EtCO2','BaseExcess', 'HCO3','pH','PaCO2','Alkalinephos', 'Calcium','Magnesium', 
'Phosphate','Potassium','PTT','Fibrinogen','Unit1','Unit2'}
df_train = df_train.assign(Unit=df_train['Unit1'] + df_train['Unit2'])
df_train_mod = df_train.drop(columns=columns_drop)
df_train_mod.columns

df_train_impute = df_train_mod.copy()
columns_impute = list(df_train_impute.columns)

grouped_by_patient = df_train_impute.groupby('Patient_ID')
df_train_impute = grouped_by_patient.apply(lambda x: x.bfill().ffill())

df_train_impute.head()

null_values = df_train_impute.isnull().mean()*100
null_values = null_values.sort_values(ascending=False)
null_values

null_col = ['TroponinI', 'Bilirubin_direct', 'AST', 'Bilirubin_total', 'Lactate', 'SaO2', 'FiO2',
            'Unit', 'Patient_ID']
df_train_impute = df_train_impute.drop(columns=null_col)
df_train_impute.columns
df_train_impute.shape

one_hot = pd.get_dummies(df_train_impute['Gender'])
df_train_impute = df_train_impute.join(one_hot)
df_train_impute = df_train_impute.drop('Gender', axis=1)

def try_gaussian(df, col):
  #print('actual plot')
  #diagnostic_plots(df,col)
  # this applies yeojohnson plot
  df['col_yj'], param = stats.yeojohnson(df[col]) 
  #print('yeojohnson plot')
 #diagnostic_plots(df, 'col_yj')
  # this applies exponential transformation
  df['col_1.5'] = df[col]**(1/1.5)
  #print('**1/1.5 plot') 
 # diagnostic_plots(df, 'col_1.5')
  df['col_.5'] = df[col]**(.5)
  #print('**.5 plot') 
  # this applies inverse transformation
  #diagnostic_plots(df, 'col_.5')
  df['col_rec'] = 1 / (df[col]+0.00001) 
  #diagnostic_plots(df, 'col_rec')
  # this applies logarithmic trasnformation
  df['col_log'] = np.log(df[col]+1)
  #diagnostic_plots(df, 'col_log')

lst = ['O2Sat', 'Temp', 'MAP', 'BUN', 'Creatinine', 'Glucose', 'WBC', 'Platelets' ]
for i in lst:
  #print(i)
  try_gaussian(df_train_impute, i)

df_train_impute = df_train_impute.drop(columns = ['col_yj','col_1.5','col_.5','col_rec','col_log'])

columns_normalized = ['MAP', 'BUN', 'Creatinine', 'Glucose', 'WBC', 'Platelets' ]
for i in columns_normalized:
  df_train_impute[i] = np.log(df_train_impute[i]+1)

scaler = StandardScaler()
df_train_impute[['HR', 'O2Sat', 'Temp', 'MAP', 'Resp', 'BUN', 'Chloride',
       'Creatinine', 'Glucose', 'Hct', 'Hgb', 'WBC', 'Platelets']] = scaler.fit_transform(df_train_impute[['HR', 'O2Sat', 'Temp', 'MAP', 'Resp', 'BUN', 'Chloride',
       'Creatinine', 'Glucose', 'Hct', 'Hgb', 'WBC', 'Platelets']])
df_train_impute.head()

df_train_impute = df_train_impute.dropna()

null_values = df_train_impute.isnull().mean()*100
null_values

def get_data_ready(df):
  columns_drop={'Unnamed: 0','SBP','DBP','EtCO2','BaseExcess', 'HCO3','pH','PaCO2','Alkalinephos', 'Calcium','Magnesium', 
  'Phosphate','Potassium','PTT','Fibrinogen','Unit1','Unit2'}
  df = df.assign(Unit=df['Unit1'] + df['Unit2'])
  # dropping columns based on redundancy
  df = df.drop(columns=columns_drop)
  grouped_by_patient = df.groupby('Patient_ID')
  # imputing backfill and forward fill
  df = grouped_by_patient.apply(lambda x: x.bfill().ffill())
  # dropping all the columns with null values more than 25% and patient_id
  null_col = ['TroponinI', 'Bilirubin_direct', 'AST', 'Bilirubin_total', 'Lactate', 'SaO2', 'FiO2','Unit', 'Patient_ID']
  df = df.drop(columns=null_col)
  # gaussian transformation
  columns_normalized = ['MAP', 'BUN', 'Creatinine', 'Glucose', 'WBC', 'Platelets' ]
  for i in columns_normalized:
    df[i] = np.log(df[i]+1)
  # normailizing
  scaler = StandardScaler()
  df[['HR', 'O2Sat', 'Temp', 'MAP', 'Resp', 'BUN', 'Chloride',
       'Creatinine', 'Glucose', 'Hct', 'Hgb', 'WBC', 'Platelets']] = scaler.fit_transform(df[['HR', 'O2Sat', 'Temp', 'MAP', 'Resp', 'BUN', 'Chloride',
       'Creatinine', 'Glucose', 'Hct', 'Hgb', 'WBC', 'Platelets']])
  # onehot encoding the gender
  one_hot = pd.get_dummies(df['Gender'])
  df = df.join(one_hot)
  df = df.drop('Gender', axis=1)
  df = df.dropna()
  return df

def evaluate_model(y_true,y_pred):
  accuracy = accuracy_score(y_true, y_pred)
  print("Accuracy:", accuracy)
  precision = precision_score(y_true, y_pred)
  print("Precision:", precision)
  recall = recall_score(y_true, y_pred)
  print("Recall:", recall)
  f1 = f1_score(y_true, y_pred)
  print("F1 Score:", f1)
  auc = roc_auc_score(y_true, y_pred)
  print("AUC-ROC:", auc)
  mae = mean_absolute_error(y_true, y_pred)
  print("Mean Absolute Error:", mae)
  rmse = np.sqrt(mean_squared_error(y_true, y_pred))
  print("Root Mean Squared Error:", rmse)
  cm = confusion_matrix(y_true, y_pred)
  sns.heatmap(cm, annot=True, fmt='d')
  plt.show()

majority_class = df_train_impute[df_train_impute['SepsisLabel'] == 0]
minority_class = df_train_impute[df_train_impute['SepsisLabel'] == 1]
print('number of sepsis label 1 is {}'.format(len(minority_class)))
print('while number of sepsis label 0 is {}'.format(len(majority_class)))

majority_class_subset = majority_class.sample(n=2*len(minority_class))
df_train_impute = pd.concat([majority_class_subset, minority_class])

majority_class = df_train_impute[df_train_impute['SepsisLabel'] == 0]
minority_class = df_train_impute[df_train_impute['SepsisLabel'] == 1]

print('number of sepsis label 1 is {}'.format(len(minority_class)))
print('while number of sepsis label 0 is {}'.format(len(majority_class)))

X = df_train_impute.drop('SepsisLabel', axis=1)
y = df_train_impute['SepsisLabel']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# X_train = X_train.values
# X_test = X_text.values
# y_train = y_train.values
# y_test = y_test.values
Xtrn = X_train.values
ytrn = y_train.values

Xtst = X_test.values
ytst = y_test.values

from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=300, random_state=0)

model.fit(Xtrn, ytrn)
#y_score = model.decision_function(Xtst)
rcf_predictions = model.predict(Xtst)
evaluate_model(ytst,rcf_predictions)
fpr, tpr, _ = roc_curve(ytst, rcf_predictions, pos_label=model.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()



from sklearn.naive_bayes import GaussianNB
model = GaussianNB()
model.fit(Xtrn, ytrn)
nbc_predictions = model.predict(Xtst)
evaluate_model(ytst,nbc_predictions)
fpr, tpr, _ = roc_curve(ytst, nbc_predictions, pos_label=model.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(penalty = 'l2',max_iter = 500)
model.fit(Xtrn, ytrn)
lr_predictions = model.predict(Xtst)
evaluate_model(ytst,lr_predictions)
fpr, tpr, _ = roc_curve(ytst, lr_predictions, pos_label=model.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

from sklearn import tree
dtree = tree.DecisionTreeClassifier()
dtree.fit(Xtrn, ytrn)
tree_predictions = dtree.predict(Xtst)
evaluate_model(ytst,tree_predictions)
fpr, tpr, _ = roc_curve(ytst, tree_predictions, pos_label=model.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

def partition(x):
    """
    Partition the column vector x into subsets indexed by its unique values (v1, ... vk)

    Returns a dictionary of the form
    { v1: indices of x == v1,
      v2: indices of x == v2,
      ...
      vk: indices of x == vk }, where [v1, ... vk] are all the unique values in the vector z.
    """

    # INSERT YOUR CODE HERE
    partition_dictionary = {}

    for key in np.unique(x):
        partition_dictionary.update({key : np.where(x==key)[0]})

    return partition_dictionary
    #raise Exception('Function not yet implemented!')
  

# function to calculate depth of the tree
def find_depth(tree, tree_depth=1):   
    for k in tree:
        if isinstance(tree[k], dict):
            tree_depth = find_depth(tree[k], tree_depth + 1)
    return tree_depth



def entropy(y):
    """
    Compute the entropy of a vector y by considering the counts of the unique values (v1, ... vk), in z

    Returns the entropy of z: H(z) = p(z=v1) log2(p(z=v1)) + ... + p(z=vk) log2(p(z=vk))
    """

    # INSERT YOUR CODE HERE
    uniqval_arr = partition(y)
    total_count = len(y)

    entropy_sum = 0

    for key in uniqval_arr.keys():
        tmp = (float)(len(uniqval_arr[key])/total_count)
        entropy_sum += -(tmp*np.log2(tmp))

    return entropy_sum
    #raise Exception('Function not yet implemented!')
    
    


def mutual_information(x, y):
    """
    Compute the mutual information between a data column (x) and the labels (y). The data column is a single attribute
    over all the examples (n x 1). Mutual information is the difference between the entropy BEFORE the split set, and
    the weighted-average entropy of EACH possible split.

    Returns the mutual information: I(x, y) = H(y) - H(y | x)
    """

    # INSERT YOUR CODE HERE
    entropy_y = entropy(y)
    totalcountforx = len(x)
    uniqval_arrforx = partition(x)

    entropy_ybyx = 0

    for k in uniqval_arrforx.keys():
        x_tmp = (float)(len(uniqval_arrforx[k]/totalcountforx))
        y_prime= [y[j] for j in uniqval_arrforx[k]]
        ybyx_prime = entropy(y_prime)
        entropy_ybyx += (x_tmp * ybyx_prime)

    final_entrpy = (entropy_y - entropy_ybyx)
    return final_entrpy
    #raise Exception('Function not yet implemented!')
    
    
def get_attribute_value_pairs(x,attribute_value_pairs):
    if (attribute_value_pairs is None):
        attribute_value_pairs = []
        for i in range (len(x[0])):
            for j in np.unique(np.array([arr[i] for arr in x])):
                attribute_value_pairs.append((i, j))
    attribute_value_pairs = np.array(attribute_value_pairs)
    return attribute_value_pairs


def get_gain(x,y,attribute_value_pairs):
    A = []
    for feat, val in attribute_value_pairs:
        feat = int(feat)
        A.append(mutual_information(np.asarray((x[:, feat] == val), dtype=int), y))
    A = np.array(A)

    return A   


def id3(x, y, attribute_value_pairs=None, depth=0, max_depth=5):
    

    y_val,y_count = np.unique(y,return_counts=True)
    attribute_value_pairs = get_attribute_value_pairs(x,attribute_value_pairs)
   
    if(len(y_val) == 1):
        return y_val[0]

    
    if(len(attribute_value_pairs) == 0 or depth == max_depth):
        a = np.argmax(y_count)
        return y_val[a]

   
    rec_tree = {}
    gain = []
  
    gain = get_gain(x,y,attribute_value_pairs)
  
    (feat, val) = attribute_value_pairs[np.argmax(gain)]
    feat = int(feat)
    split = partition(np.array(np.asarray((x[:, feat] == val), dtype=int)))
   
    attribute_value_pairs = np.delete(attribute_value_pairs, np.argmax(gain), 0)

    for value, idx in split.items():
        x_subset = x.take(np.array(idx), axis=0)
        y_subset = y.take(np.array(idx), axis=0)
      
        rec_tree[(feat, val, bool(value))] = id3(x_subset, y_subset, attribute_value_pairs=attribute_value_pairs, depth=depth+1, max_depth=max_depth)

    return rec_tree

    
    


    
def predict_example(x, tree):
    
    
    for node,subtree in tree.items():
        
        attribute_index = node[0]
        attribute_value = node[1]
        attribute_decision = node[2]

        if attribute_decision == (x[attribute_index] == attribute_value):
            if type(subtree) is dict:
                return predict_example(x,subtree)
            else:
                return subtree
                
               

def compute_error(y_true, y_pred):
   
    n = len(y_true)
    error = (1/n) * sum(y_true != y_pred)
    return error
    
    

def visualize(tree, depth=0):
    

    if depth == 0:
        print('TREE')

    for index, split_criterion in enumerate(tree):
        sub_trees = tree[split_criterion]

        # Print the current node: split criterion
        print('|\t' * depth, end='')
        print('+-- [SPLIT: x{0} = {1}]'.format(split_criterion[0], split_criterion[1]))

        # Print the children
        if type(sub_trees) is dict:
            visualize(sub_trees, depth + 1)
        else:
            print('|\t' * (depth + 1), end='')
            print('+-- [LABEL = {0}]'.format(sub_trees))

#trn_err = []
#tst_err = []
#depth = []

#for p in range(1,5):
decision_tree = id3(Xtrn, ytrn, max_depth=5)
#depth.append(p)
# Compute the training & test error
y_tr_pred = [predict_example(x, decision_tree) for x in Xtrn]
trn_err = compute_error(ytrn, y_tr_pred)*100
#trn_err.append((compute_error(ytrn, y_tr_pred)*100))
y_pred = [predict_example(x, decision_tree) for x in Xtst]
tst_err = (compute_error(ytst, y_pred)*100)
#tst_err.append((compute_error(ytst, y_pred)*100))
print(trn_err)
print(tst_err)            
#print the train & test error for differnt depths
#print('Depth:',p)
#print('   Train Error = {0:4.2f}%.'.format(trn_err[-1]))
#print('   Test Error = {0:4.2f}%.'.format(tst_err[-1]))

visualize(decision_tree,5)

#tree_predict = dtree.predict(Xtst)
evaluate_model(ytst,y_pred)
fpr, tpr, _ = roc_curve(ytst, y_pred, pos_label=model.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

decision_tree = id3(Xtrn, ytrn, max_depth=10)
y_tr_pred = [predict_example(x, decision_tree) for x in Xtrn]
trn_err = compute_error(ytrn, y_tr_pred)*100

y_pred = [predict_example(x, decision_tree) for x in Xtst]
tst_err = (compute_error(ytst, y_pred)*100)

print(trn_err)
print(tst_err)  
#tree_pred = decision_tree.predict(Xtst)
visualize(decision_tree,10)
evaluate_model(ytst,y_pred)
fpr, tpr, _ = roc_curve(ytst,y_pred, pos_label=model.classes_[1])
roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()

class LogisticRegression:
    def __init__(self, lr=0.1, num_iters=2000):
        self.lr = lr
        self.num_iters = num_iters
        self.weights = None
        self.bias = None
    
    def sigmoid(self, z):
        z = np.clip(z, -500, 500)
        return 1 / (1 + np.exp(-z))
    
    def binary_cross_entropy_loss(self, y, y_hat):
        loss = -(y * np.log(y_hat + 1e-7) + (1 - y) * np.log(1 - y_hat + 1e-7))
        return loss
    
    def fit(self, X, y):
        num_samples, num_features = X.shape
        self.weights = np.zeros(num_features)
        self.bias = 0
        
        for i in range(self.num_iters):
            # forward propagation
            linear_model = np.dot(X, self.weights) + self.bias
            y_pred = self.sigmoid(linear_model)
            loss = self.binary_cross_entropy_loss(y, y_pred)
            
            # backward propagation
            dw = (1 / num_samples) * np.dot(X.T, (y_pred - y))
            db = (1 / num_samples) * np.sum(y_pred - y)
            
            # update weights and bias
            self.weights -= self.lr * dw
            self.bias -= self.lr * db
    
    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_pred = self.sigmoid(linear_model)
        y_pred_class = [1 if i > 0.5 else 0 for i in y_pred]
        return y_pred_class

lr = LogisticRegression()
lr.fit(Xtrn, ytrn)

y_pred = lr.predict(Xtst)
evaluate_model(ytst,y_pred)

class LogisticRegressionReg:
    def __init__(self, learning_rate=0.1, num_iterations=3000, lambda_reg=0.01):
        self.learning_rate = learning_rate
        self.num_iterations = num_iterations
        self.lambda_reg = lambda_reg
        
    def sigmoid(self, z):
        z = np.clip(z, -500, 500)
        return 1 / (1 + np.exp(-z))
    
    def cost_function(self, X, y, w):
        m = X.shape[0]
        z = np.dot(X, w)
        h = self.sigmoid(z)
        J = (-1/m) * np.sum(y * np.log(h + 1e-7) + (1 - y) * np.log(1 - h + 1e-7))
        reg = (self.lambda_reg / (2 * m)) * np.sum(w**2)
        J += reg
        return J
    
    def fit(self, X, y):
        m, n = X.shape
        X = np.concatenate([np.ones((m, 1)), X], axis=1)
        y = y.reshape(-1, 1)
        w = np.zeros((n+1, 1))
        
        for i in range(self.num_iterations):
            z = np.dot(X, w)
            h = self.sigmoid(z)
            grad = (1/m) * np.dot(X.T, (h - y))
            reg = (self.lambda_reg / m) * w
            reg[0] = 0  # Exclude regularization for bias term
            grad += reg
            w -= self.learning_rate * grad
            
            if i % 100 == 0:
                J = self.cost_function(X, y, w)
                print("Cost after iteration {}: {}".format(i, J))
                
        self.w = w
        
    def predict(self, X):
        m = X.shape[0]
        X = np.concatenate([np.ones((m, 1)), X], axis=1)
        z = np.dot(X, self.w)
        y_pred = self.sigmoid(z)
        y_pred_class = np.where(y_pred >= 0.5, 1, 0)
        return y_pred_class

lrreg = LogisticRegressionReg()
lrreg.fit(Xtrn, ytrn)

y_pred = lrreg.predict(Xtst)
evaluate_model(ytst,y_pred)

import xgboost as xgb
dtrain = xgb.DMatrix(Xtrn, label=ytrn)
dtest = xgb.DMatrix(Xtst, label=ytst)
param = {
    'max_depth': 5,  
    'eta': 0.3,  
    'silent': 1,  
    'objective': 'binary:logistic'}  
num_round = 100
bst = xgb.train(param, dtrain, num_round)
xgb_predictions = bst.predict(dtest)
prediction = []
for i in xgb_predictions:
  if i<0.5:
    prediction.append(0)
  else:
    prediction.append(1)
evaluate_model(y_test,prediction)

from sklearn.neural_network import MLPClassifier
nn = MLPClassifier(hidden_layer_sizes=(20,20,20), max_iter=1000,activation = 'relu',solver='adam',random_state=1)
nn.fit(Xtrn, ytrn)
y_pred = nn.predict(Xtst)
evaluate_model(ytst,y_pred)
